{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Demo project",
   "id": "230d53cdc73ab92c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "%pip install pandas numpy statsmodels scikit-learn shap matplotlib altair\n",
   "id": "56e12384027ac454",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Generate clinical and genetic features to test and save them for the record",
   "id": "1b3561a60dbbad97"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#%pip install pandas \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define gene list and feature types\n",
    "genes = [\n",
    "    \"APC\", \"ATM\", \"AXIN2\", \"BAP1\", \"BARD1\", \"BMPR1A\", \"BRCA1\", \"BRCA2\", \"BRIP1\",\n",
    "    \"CDH1\", \"CDK4\", \"CDKN2A\", \"CDKN2B\", \"CDKN1B\", \"CHECK2\", \"CTNNA1\", \"DICER1\",\n",
    "    \"EPCAN\", \"FH\", \"FLCN\", \"GREM1\", \"HOXB13\", \"KIT\", \"MAX\", \"MEN1\", \"MET\", \"MITF\",\n",
    "    \"MLH\", \"MSH2\", \"MSH3\", \"MSH6\", \"MUTYH\", \"NF1\", \"NTHL1\", \"PALB2\", \"PDGFRQ\",\n",
    "    \"PMS2\", \"POLD1\", \"POLE\", \"PTEN\", \"PTCH1\", \"RAD51C\", \"RAD51D\", \"RED\", \"SDHA\",\n",
    "    \"SDHAF2\", \"SDHB\", \"SDHC\", \"SDHD\", \"SMAD4\", \"STK11\", \"TMEM127\", \"TP53\", \"TSC2\", \"VHL\"\n",
    "]\n",
    "\n",
    "# Create random test data for genomic features\n",
    "num_samples = 100\n",
    "genomic_data = {\n",
    "    f\"{gene}_exp\": np.random.randint(0, 2, num_samples) for gene in genes\n",
    "}\n",
    "genomic_data.update({\n",
    "    f\"{gene}_cn\": np.random.randint(0, 2, num_samples) for gene in genes\n",
    "})\n",
    "genomic_data.update({\n",
    "    f\"{gene}\": np.random.randint(0, 2, num_samples) for gene in genes\n",
    "})\n",
    "genomic_features = pd.DataFrame(genomic_data)\n",
    "\n",
    "# Create random test data for clinical features\n",
    "clinical_features = pd.DataFrame({\n",
    "    f\"lab_test_{i}\": np.random.randint(0, 2, num_samples) for i in range(1, 21)\n",
    "})\n",
    "\n",
    "# Add a random binary target for testing\n",
    "genomic_features['target_column'] = np.random.randint(0, 2, num_samples)\n",
    "\n",
    "#save the generated features\n",
    "genomic_features.to_csv('./data/genomic_features.csv')\n",
    "clinical_features.to_csv('./data/clinical_features.csv')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load data and prepare the feature matrix. It is a good idea to QC your features before using them as input, check key distributions, test for bias and data drift",
   "id": "32891ae36796fd41"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import shap\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load your data\n",
    "genomic_features = pd.read_csv('./data/genomic_features.csv')\n",
    "clinical_features = pd.read_csv('./data/clinical_features.csv')\n",
    "# Combine the datasets\n",
    "data = pd.concat([genomic_features, clinical_features], axis=1)\n",
    "\n",
    "# Define target variable and features\n",
    "# Replace 'target_feature' with the name of the target column\n",
    "target_feature = 'target_column'  # Change this\n",
    "X = data.drop(columns=[target_feature])\n",
    "y = data[target_feature]\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n"
   ],
   "id": "9f110617427855be",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Train a model (Random Forest)\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Explain the model's predictions using SHAP\n",
    "explainer = shap.TreeExplainer(random_forest)\n",
    "shap_values = explainer.shap_values(X_test)"
   ],
   "id": "b12ad6a274822f35",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Plot SHAP plot. \n",
    "### Since a random forest is essentially an ensemble of decision trees, SHAPâ€™s TreeExplainer can leverage the tree structure to calculate Shapley values more quickly and accurately than generic approaches (like the KernelExplainer)"
   ],
   "id": "41a339fc9d89be74"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Extract SHAP values for class 1 directly\n",
    "shap_values_class_1 = shap_values[:, :, 1]  # Extract class 1 values\n",
    "\n",
    "# Check the shapes\n",
    "print(\"SHAP values for class 1 shape:\", shap_values_class_1.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "\n",
    "# Ensure shapes match\n",
    "assert shap_values_class_1.shape == X_test.shape, \"SHAP values shape does not match X_test shape\"\n",
    "\n",
    "# Plot SHAP summary for class 1\n",
    "shap.summary_plot(shap_values_class_1, X_test)\n"
   ],
   "id": "b2b632131ef768f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Calculate VIF (for logistic regression)",
   "id": "4fe05d590daadfee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "def compute_vif(X):\n",
    "    \"\"\"Calculate VIF for each feature in the dataset.\"\"\"\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Feature\"] = X.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    return vif_data\n",
    "\n",
    "vif_results = compute_vif(X)\n",
    "\n",
    "# Display features with VIF < 10\n",
    "vif_results_below_10 = vif_results[vif_results['VIF'] < 10]\n",
    "print(vif_results_below_10)"
   ],
   "id": "7b848be37e7bafab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Calculate correlation matrix, drop highly correlated features",
   "id": "4cd618cb68c9f329"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calculate the correlation matrix\n",
    "corr_matrix = X.corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Find features with correlation greater than 0.9\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.9)]\n",
    "\n",
    "# Drop highly correlated features\n",
    "X = X.drop(columns=to_drop)\n",
    "\n",
    "print(f\"Removed features due to high correlation: {to_drop}\")\n"
   ],
   "id": "63bb25e3c27aefed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Check that the target column is binary and recalculate VIF",
   "id": "5781871869c0beb4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Ensure target column is binary (e.g., values 0 and 1)\n",
    "print(f\"Unique values in the target column: {y.unique()}\")\n"
   ],
   "id": "d0df83496e72708e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#Perform WALD test",
   "id": "4cc567d82c55fb73"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Recalculate VIF\n",
    "vif_results = compute_vif(X)\n",
    "print(vif_results)\n",
    "\n",
    "# Refit the logistic regression model\n",
    "X = sm.add_constant(X)  # Add intercept\n",
    "logit_model = sm.Logit(y, X)\n",
    "result = logit_model.fit()\n",
    "\n",
    "# Perform Wald's test\n",
    "wald_results = pd.DataFrame({\n",
    "    \"Feature\": X.columns,\n",
    "    \"Coefficient\": result.params,\n",
    "    \"Std Err\": result.bse,\n",
    "    \"z-Score\": result.tvalues,\n",
    "    \"p-Value\": result.pvalues\n",
    "})\n",
    "\n",
    "print(wald_results)\n"
   ],
   "id": "409c81ebabff8eae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Apply L2 regularization",
   "id": "132ff90232229d9a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Apply L2 regularization\n",
    "linear_reg = LogisticRegression(penalty='l2', solver='liblinear')\n",
    "linear_reg.fit(X_train, y_train)\n",
    "\n",
    "# Check coefficients and perform significance testing\n",
    "print(f\"Coefficients: {linear_reg.coef_}\")\n"
   ],
   "id": "28a27f803d3c8561",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train ElasticNet model (Lasso and Ridge Regression)",
   "id": "c8ee7979233f0524"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Split data into train and test sets\n",
    "\n",
    "# Apply Elastic Net with Cross-Validation to find the best alpha and L1 ratio\n",
    "elastic_net = ElasticNetCV(l1_ratio=[0.1, 0.5, 0.9],  # Mix of L1 (LASSO) and L2 (ridge)\n",
    "                           alphas=[0.1, 0.01, 0.001],  # Regularization strengths\n",
    "                           cv=6,                       # 5-fold cross-validation\n",
    "                           random_state=1248)\n",
    "\n",
    "# Fit the model\n",
    "elastic_net.fit(X_train, y_train)\n",
    "\n",
    "# Display the best alpha and l1_ratio\n",
    "print(\"Optimal alpha:\", elastic_net.alpha_)\n",
    "print(\"Optimal L1 ratio:\", elastic_net.l1_ratio_)\n",
    "\n",
    "# Coefficients from the model\n",
    "coefficients = pd.DataFrame({\n",
    "    \"Feature\": X_train.columns,\n",
    "    \"Coefficient\": elastic_net.coef_\n",
    "})\n",
    "\n",
    "# Display coefficients\n",
    "print(coefficients)\n"
   ],
   "id": "da6ee2caa42360b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Predict on the models constructed and calculate performance metrics: MSE, R2, AUC, ROC_Curves, RMSE, MAE",
   "id": "bd962495ca109db4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, roc_curve, auc\n",
    "\n",
    "y_pred_en = elastic_net.predict(X_test)\n",
    "y_pred_rf = random_forest.predict(X_test)\n",
    "y_pred_lr = linear_reg.predict(X_test)\n",
    "\n",
    "# If using ROC/AUC, ensure predictions are probabilities or at least [0,1].\n",
    "# This is a simplification; for real classification tasks, use classifiers and predict_proba.\n",
    "y_pred_en_proba = np.clip(y_pred_en, 0, 1)\n",
    "y_pred_rf_proba = np.clip(y_pred_rf, 0, 1)\n",
    "y_pred_lr_proba = np.clip(y_pred_lr, 0, 1)\n",
    "\n",
    "# Calculate metrics\n",
    "mse_en = mean_squared_error(y_test, y_pred_en)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "\n",
    "r2_en = r2_score(y_test, y_pred_en)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "mae_en = mean_absolute_error(y_test, y_pred_en)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
    "\n",
    "rmse_en = np.sqrt(mse_en)\n",
    "rmse_rf = np.sqrt(mse_rf)\n",
    "rmse_lr = np.sqrt(mse_lr)\n",
    "\n",
    "# If classification, compute ROC/AUC:\n",
    "fpr_en, tpr_en, thresh_en = roc_curve(y_test, y_pred_en_proba)\n",
    "fpr_rf, tpr_rf, thresh_rf = roc_curve(y_test, y_pred_rf_proba)\n",
    "fpr_lr, tpr_lr, thresh_lr = roc_curve(y_test, y_pred_lr_proba)\n",
    "\n",
    "roc_auc_en = auc(fpr_en, tpr_en)\n",
    "roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
    "roc_auc_lr = auc(fpr_lr, tpr_lr)\n",
    "\n",
    "# Create DataFrame for regression metrics\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Model': ['Elastic Net', 'Random Forest', 'Linear Regression'],\n",
    "    'MSE': [mse_en, mse_rf, mse_lr],\n",
    "    'R2': [r2_en, r2_rf, r2_lr],\n",
    "    'MAE': [mae_en, mae_rf, mae_lr],\n",
    "    'RMSE': [rmse_en, rmse_rf, rmse_lr]\n",
    "})\n",
    "\n",
    "# Melt into long format\n",
    "metrics_long = metrics_df.melt(id_vars='Model', var_name='Metric', value_name='Value')\n",
    "\n",
    "\n"
   ],
   "id": "420f3e3a5d1d2902",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create bar charts for each metric\n",
    "metrics_chart = alt.Chart(metrics_long).mark_bar().encode(\n",
    "    x=alt.X('Model:N', title='Model'),\n",
    "    y=alt.Y('Value:Q', title='Value'),\n",
    "    color='Model:N',\n",
    "    column='Metric:N',\n",
    "    tooltip=['Model', 'Metric', 'Value']\n",
    ").properties(\n",
    "    title='Model Performance Comparison'\n",
    ")\n",
    "\n",
    "# Create DataFrame for ROC curves\n",
    "roc_df = pd.DataFrame({\n",
    "    'False Positive Rate': np.concatenate([fpr_en, fpr_rf, fpr_lr]),\n",
    "    'True Positive Rate': np.concatenate([tpr_en, tpr_rf, tpr_lr]),\n",
    "    'Model': (['Elastic Net'] * len(fpr_en)) +\n",
    "             (['Random Forest'] * len(fpr_rf)) +\n",
    "             (['Linear Regression'] * len(fpr_lr))\n",
    "})\n",
    "\n",
    "# ROC curve chart\n",
    "roc_chart = alt.Chart(roc_df).mark_line().encode(\n",
    "    x=alt.X('False Positive Rate:Q', title='False Positive Rate'),\n",
    "    y=alt.Y('True Positive Rate:Q', title='True Positive Rate'),\n",
    "    color='Model:N',\n",
    "    tooltip=['Model', 'False Positive Rate', 'True Positive Rate']\n",
    ").properties(\n",
    "    title=f'ROC Curves (AUC - EN: {roc_auc_en:.2f}, RF: {roc_auc_rf:.2f}, LR: {roc_auc_lr:.2f})'\n",
    ")\n",
    "\n",
    "# Combine all charts\n",
    "# Top: Metrics charts (MSE, R2, MAE, RMSE in columns)\n",
    "# Bottom: ROC chart\n",
    "final_chart = (metrics_chart & roc_chart).resolve_scale(color='independent')\n",
    "final_chart\n"
   ],
   "id": "9ba8e06a9cd6f43",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Save to HTML if the charts did not render in the notebook\n",
    "final_chart.save('./plots/metrics_comparison2.html')\n",
    "print(\"Charts saved to metrics_comparison2.html\")"
   ],
   "id": "9947d04ed702ed92",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Reinitialize models, retrain, adjust models if needed and generate new predictions. \n",
    "#### Make sure you normalize and QC the features thoroughly before using them as input in the model. Check the training/testing set and the distributions of key metrics."
   ],
   "id": "bd894e1426af4db8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialize models\n",
    "elastic_net = ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=42)\n",
    "random_forest = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "linear_reg = LinearRegression()\n",
    "\n",
    "# Fit models\n",
    "elastic_net.fit(X_train, y_train)\n",
    "random_forest.fit(X_train, y_train)\n",
    "linear_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_en = elastic_net.predict(X_test)\n",
    "y_pred_rf = random_forest.predict(X_test)\n",
    "y_pred_lr = linear_reg.predict(X_test)"
   ],
   "id": "89ff8ae91b819cba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "cc377b243b23992f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
